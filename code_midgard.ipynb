{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import geocoder\n",
    "from googlemaps import Client as GoogleMaps\n",
    "import googlemaps\n",
    "import gmaps\n",
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "api_key = \"***\" #for_geocoder\n",
    "gmaps = googlemaps.Client(key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'midgard.csv'\n",
    "df = (\n",
    "    pd.read_csv(path, names = ['name', 'surname', 'email', 'mailto', 'contact', 'street', 'city', 'index', 'y', 'date', 'item'])\n",
    "\n",
    ") #give the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns\n",
    "df['full_address'] = df['street']+', '+df['city']\n",
    "df['long'] = \"\"\n",
    "df['lat'] = \"\"\n",
    "df['proper_address'] = \"\"\n",
    "df['country'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip the step of cleaning the address because Google will return formatted_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['full_address']) \n",
    "\n",
    "results = []\n",
    "for i, row in df_unique.iterrows():\n",
    "    full_address = row[\"full_address\"]\n",
    "    print(full_address)\n",
    "    \n",
    "    if pd.isnull(full_address):  #Google API gives error when value is nan\n",
    "        continue \n",
    "    \n",
    "    geocode_result = gmaps.geocode(full_address)\n",
    "    if not geocode_result:    #later some other problems appeared like error 400 \n",
    "        continue\n",
    "\n",
    "    geocode_info = geocode_result[0]\n",
    "    loc = geocode_info.get('geometry', {}).get('location', {})  #it gives you structured data but every key is called 'long name'\n",
    "    \n",
    "    if not loc:\n",
    "        continue\n",
    "    \n",
    "    address_components = geocode_info.get('address_components', [])\n",
    "    country = next((component['long_name'] for component in address_components if 'country' in component['types']), None)\n",
    "    results.append({\n",
    "        \"row_number\": row[\"row_number\"],\n",
    "        \"full_address\": full_address,\n",
    "        \"lat\": loc.get('lat'),\n",
    "        \"long\": loc.get('lng'),\n",
    "        \"formatted_address\": geocode_info.get('formatted_address'),\n",
    "        \"country\": country\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged formatted_address, lat, lng, country with a df_unique with unique values\n",
    "df_unique = df_unique.merge(pd.DataFrame(results),\n",
    "        on=\"full_address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I saw no other issues, so didn't do regex\n",
    "df_unique['name'] = df_unique['name'].str.lower()\n",
    "df_unique['name'] = df_unique['name'].str.strip()\n",
    "\n",
    "df_unique['surname'] = df_unique['surname'].str.strip()\n",
    "df_unique['surname'] = df_unique['surname'].str.lower()\n",
    "\n",
    "\n",
    "df_unique['full_name'] = df_unique['name']+' '+df_unique['surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('midgard_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polish_df = df_unique[df_unique['country_y'] == 'Poland']\n",
    "len(polish_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polish_df['full_name'].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
